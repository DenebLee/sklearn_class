{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict에서 k, v에 접근하는 방법\n",
    "- d['k'] = v\n",
    "- v = d['k']\n",
    "\n",
    "bunch는 key를 마치 attribute처럼 사용할 수 있도록해준다.\n",
    "- b.k = v\n",
    "- v = b.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정계수 : 0.6844267283527083\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X_test, y_test)\n",
    "print(f\"결정계수 : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^2 = 1- \\cfrac {SSE}{SST}$$\n",
    "- $SST = \\sum_i (y - \\bar y)^2$ : Sum of Square Total (Variance)\n",
    "- $SSE = \\sum_i (y - \\hat y)^2$ : Sum of Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6844267283527083"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "SST = np.square(y_test - y_test.mean()).sum()\n",
    "SSE = np.square(y_test - yhat).sum()\n",
    "\n",
    "R2 = 1 - SSE/SST\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X의 shape이 (n, p)라면:\n",
    "\n",
    "$$\\begin{align}\n",
    "SST &= SSE + SSR\\\\\n",
    "\\sum_i (y_i - \\bar y)^2 &= \\sum_i (y_i - \\hat y_i + \\hat y_i - \\bar y)^2 \\\\\n",
    "\\sum_i (y_i - \\bar y)^2 &= \\sum_i (y_i - \\hat y_i)^2 + \\sum_i (\\hat y_i - \\bar y)^2\\\\\n",
    "\\text{DoF} : (n - 1) &= (n - p - 1) + (p )\n",
    "\\end{align}$$\n",
    "\n",
    "- $\\hat y = X \\cdot W + b$\n",
    "- MSE(Mean Squared Error) : $\\cfrac {SSE}{n-p-1}$\n",
    "- $y = \\hat y + \\epsilon$, 잔차 $\\epsilon$의 분산값 $\\sigma_e^2 = MSE$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "Loss(w) &= \\sum_i \\epsilon^2 = \\sum_i (y - \\hat y)^2 \\\\\n",
    "&= (y - X \\cdot w)^T \\cdot (y - X \\cdot w)\\\\\n",
    "\\cfrac {\\partial Loss}{\\partial w} &= 2 (X^T \\cdot X) \\cdot w - 2X^T \\cdot y \\\\\n",
    "w(t+1) &= w(t) - \\text{lr} * \\cfrac {\\partial Loss}{\\partial w} \\Bigg|_{w =w(t)}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] 보스턴 집값 데이터의 train data에 대한 $R^2$을 구하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748087259862344"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2train = model.score(X_train, y_train)\n",
    "R2train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] 임의의 noise 데이터를 추가할 때, 학습 데이터에서의 $R^2$은 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 데이터에서 학습 결정계수: 0.748, 테스트 결정계수: 0.684\n",
      "노이즈 데이터에서 학습 결정계수: 0.754, 테스트 결정계수: 0.679\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.randint(5, 30, (data.data.shape[0], 5))\n",
    "newX = np.hstack([noise, data.data])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(newX, data.target, random_state=42)\n",
    "m = LinearRegression()\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "R2newTr = m.score(X_train, y_train)\n",
    "R2newTe = m.score(X_test, y_test)\n",
    "print(\"기본 데이터에서 학습 결정계수: %.3f, 테스트 결정계수: %.3f\" %(R2train, score))\n",
    "print(\"노이즈 데이터에서 학습 결정계수: %.3f, 테스트 결정계수: %.3f\" %(R2newTr, R2newTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 머신러닝에서 일반적으로 변수의 수가 많아지면 변수로부터 불필요한 정보를 습득하려는 경향이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.28322638e-01,  2.95517751e-02,  4.88590934e-02,  2.77350326e+00,\n",
       "       -1.62388292e+01,  4.36875476e+00, -9.24808158e-03, -1.40086668e+00,\n",
       "        2.57761243e-01, -9.95694820e-03, -9.23122944e-01,  1.31854199e-02,\n",
       "       -5.17639519e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] 상관성있는 데이터에서의 결정계수와 회귀계수의 변화\n",
    "- 보스턴 데이터에서 아래와 같이 2개의 변수를 추가하고\n",
    " - CN = 5\\*CRIM - 5\\*NOX, \n",
    " - RA = 6\\*RM - 3\\*AGE + CRIM\n",
    "- newX2라는 데이터를 생성하고, \n",
    "- 이 데이터로부터 학습과 테스트 데이터를 나누어서, 각각에 대한 $R^2$을 구하여라.\n",
    "- 그리고 변화된 회귀계수를 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRIM, NOX, RM, AGE = data.data[:,0], data.data[:,4], data.data[:,5], data.data[:,6]\n",
    "CN, RA = 5*CRIM - 5*NOX, 6*RM - 3*AGE + CRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX2 = np.hstack([data.data, CN.reshape((-1,1)), RA.reshape((-1,1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 데이터에서 학습 결정계수: 0.748, 테스트 결정계수: 0.684\n",
      "추가 데이터에서 학습 결정계수: 0.748, 테스트 결정계수: 0.684\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newX2, data.target, random_state=42)\n",
    "m2 = LinearRegression()\n",
    "m2.fit(X_train, y_train)\n",
    "\n",
    "R2newTr = m2.score(X_train, y_train)\n",
    "R2newTe = m2.score(X_test, y_test)\n",
    "print(\"기본 데이터에서 학습 결정계수: %.3f, 테스트 결정계수: %.3f\" %(R2train, score))\n",
    "print(\"추가 데이터에서 학습 결정계수: %.3f, 테스트 결정계수: %.3f\" %(R2newTr, R2newTe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.28322638e-01,  2.95517751e-02,  4.88590934e-02,  2.77350326e+00,\n",
       "       -1.62388292e+01,  4.36875476e+00, -9.24808158e-03, -1.40086668e+00,\n",
       "        2.57761243e-01, -9.95694820e-03, -9.23122944e-01,  1.31854199e-02,\n",
       "       -5.17639519e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.22528436,  0.02955178,  0.04885909,  2.77350326, -8.53349762,\n",
       "        2.01897366,  1.16564247, -1.40086668,  0.25776124, -0.00995695,\n",
       "       -0.92312294,  0.01318542, -0.51763952,  1.54106631,  0.39163018])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 수집한 데이터에서:\n",
    "1. 임의의 노이즈가 주는 영향:\n",
    " - 학습 정확도는 올라가고, 테스트 정확도는 내려간다.\n",
    " - 모델의 정확도는 낮아진다.\n",
    "2. 변수간의 상관성이 높은 경우, 변수간에 중복된 정보를 가지는 경우\n",
    " - 회귀계수의 단위가 커지게 된다.\n",
    " - 이유는 중복되지 않는 정보(작은량의 정보)를 빼내기 위해\n",
    " - 중복된 정보간의 큰 차이를 만들어서 작은 정보를 빼내려고 합니다.\n",
    " - 회귀계수를 크게 만들어야 이런 작업을 할 수 있다.\n",
    " \n",
    "각각의 변수 $X_1 = 0.1*A + \\alpha$, $X_2 = -5*A + \\beta$, $X_0 = A$의 정보량이다. 이때, A라는 정보는 3 변수에 서로 중복되어 있고, 이때 $\\alpha$와 $\\beta$라는 정보를 빼내려면, 다음과 같은 작업을 회귀모델에서는 수행하게 된다.\n",
    "- $\\alpha = X_1 - 0.1 * X_0$\n",
    "- $\\beta = X_2 + 5*X_0$\n",
    "\n",
    "일반적으로 우리가 수집한 데이터는 위와 같이 노이즈도 가지고 있고, 중복된 정보도 가지게된다. 이를 통해 노이즈를 학습하려고 하면 할 수록, 회귀계수가 커지는 경향이 있다. 이를 다중공선성 문제라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중공선성 문제\n",
    "이러한 다중공선성 문제를 해결하기 위한 2가지 방법:\n",
    "1. Ridge Regression : L2 규제화된 Linear Regression\n",
    "2. Lasso Regression : L1 규제화된 LInear Regression\n",
    "\n",
    "위 2가지 방법은 결국 작은 노이즈까지 학습하는 것을 방지하기 위해 w이 절대값이 커지는 것을 방지(규제)하는 방법을 사용합니다.\n",
    "\n",
    "Ridge Regression:\n",
    "$$Loss(w) = \\sum_i (y - \\hat y)^2 + \\alpha ||w||^2$$\n",
    "- 상대적으로 정확도가 높다\n",
    "\n",
    "Lasso Regression:\n",
    "$$Loss(w) = \\sum_i (y - \\hat y)^2 + \\alpha |w|$$\n",
    "- 더 적은 변수로 예측이 가능하다. (덜 중요한 변수는 포기)\n",
    "- 예측시간이 빠르다. 더 좋은 장점을 갖다.\n",
    "- 사업적용이 용이하다.\n",
    "\n",
    "ElasticNet Regression:\n",
    "$$Loss(w) = \\sum_i (y - \\hat y)^2 + \\alpha (\\beta|w| + (1-\\beta)||w||^2)$$\n",
    "\n",
    "w ~ 0.1\n",
    "- Ridge 규제항: $|w|^2 \\sim 0.01$ => 대부분 변수의 weight를 작은 값.\n",
    "- Lasso 규제항: $|w| \\sim 0.1$ => 설명력이 낮은 변수들의 weight ~ 0\n",
    "\n",
    "---\n",
    "규제항을 도입한 Ridge, Lasso의 공통적인 단점:\n",
    "1. 기존 Loss인 MSE와 |W|에 대한 규제간의 weight factor인 $\\alpha$를 튜닝해야 함.\n",
    " - 튜닝이란? 우리가 가지고 있는 데이터 X, y에 적합한 $\\alpha$를 찾는 일\n",
    " - 여러개의 $\\alpha$를 가지고 있는 모델을 학습해서, 테스트 데이터에서의 $R^2$가 더 좋은 것을 선택하는 일\n",
    "2. p 개의 변수들을 모두 동일한 스케일로 맞추어야 한다. Scaling이라 한다.\n",
    " - 큰 단위로 측정한 작은값변수와 작은 단위로 측정한 큰값변수가 있을 때\n",
    " - 큰 단위로 측정한 작은값변수의 weight는 커져야 하는데, 규제항에 의해 그 중요도(weight)를 줄일 수 밖에 없고, 어떤 경우는 그 정보를 상실하게 된다.\n",
    " - 이는 Ridge, Lasso 모두 모든 회귀계수에 일률적인 규제강도 $\\alpha$를 가지기 때문\n",
    " - 변수의 스케일 간의 차이에 의해 발생하는 이러한 문제를 해결하기 위해서는 학습전 모든 변수들을 같은 스케일을 가지도록 조정해줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge, Lasso 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge나 Lasso의 경우 회귀계수 즉, 입력변수에 대한 weight에 대한 규제를 갖기 때문에, 입력변수들에 대한 동등한 규제를 위해 입력변수들에 대한 scaling이 필요하다.\n",
    "\n",
    "당뇨병 데이터의 경우, 아래와같이 모든 변수들이 정규화되어 있기 때문에 따라 scaling을 필요로하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.63428493e-16,  1.30834257e-16, -8.04534920e-16,  1.28165452e-16,\n",
       "       -8.83531559e-17,  1.32702421e-16, -4.57464634e-16,  3.77730150e-16,\n",
       "       -3.83085422e-16, -3.41288202e-16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04756515, 0.04756515, 0.04756515, 0.04756515, 0.04756515,\n",
       "       0.04756515, 0.04756515, 0.04756515, 0.04756515, 0.04756515])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4384009113704955"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37914194389255096"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=1.0)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004438373013188945"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha=1.0, l1_ratio=.5)\n",
    "elastic.fit(X_train, y_train)\n",
    "elastic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $R^2 = 1 - \\cfrac {SSE}{SST}< 0$ : SSE가 SSR보다 크다는 것을 의미\n",
    "- y의 값을 y의 평균값으로 예측하는 dummy 모델보다 않좋다는 것을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x224879b7048>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = elastic.predict(X_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화 선형회귀 모델별 가중치(계수) 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>47.746571</td>\n",
       "      <td>-241.991804</td>\n",
       "      <td>531.968569</td>\n",
       "      <td>381.565299</td>\n",
       "      <td>-918.490206</td>\n",
       "      <td>508.251474</td>\n",
       "      <td>116.940405</td>\n",
       "      <td>269.485086</td>\n",
       "      <td>695.806221</td>\n",
       "      <td>26.323431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>50.551555</td>\n",
       "      <td>-67.722365</td>\n",
       "      <td>278.300728</td>\n",
       "      <td>197.624014</td>\n",
       "      <td>-6.245973</td>\n",
       "      <td>-26.226985</td>\n",
       "      <td>-151.394518</td>\n",
       "      <td>120.323196</td>\n",
       "      <td>215.854694</td>\n",
       "      <td>101.755543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>398.384368</td>\n",
       "      <td>46.178843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>238.187402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elastic</th>\n",
       "      <td>0.413088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.298991</td>\n",
       "      <td>2.256939</td>\n",
       "      <td>0.339380</td>\n",
       "      <td>0.080784</td>\n",
       "      <td>-1.874661</td>\n",
       "      <td>2.143869</td>\n",
       "      <td>2.947964</td>\n",
       "      <td>1.701981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age         sex         bmi          bp          s1  \\\n",
       "linear   47.746571 -241.991804  531.968569  381.565299 -918.490206   \n",
       "ridge    50.551555  -67.722365  278.300728  197.624014   -6.245973   \n",
       "lasso     0.000000   -0.000000  398.384368   46.178843    0.000000   \n",
       "elastic   0.413088    0.000000    3.298991    2.256939    0.339380   \n",
       "\n",
       "                 s2          s3          s4          s5          s6  \n",
       "linear   508.251474  116.940405  269.485086  695.806221   26.323431  \n",
       "ridge    -26.226985 -151.394518  120.323196  215.854694  101.755543  \n",
       "lasso      0.000000   -0.000000    0.000000  238.187402    0.000000  \n",
       "elastic    0.080784   -1.874661    2.143869    2.947964    1.701981  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "linear = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "coefs = np.vstack((linear.coef_, ridge.coef_, lasso.coef_, elastic.coef_))\n",
    "\n",
    "coefs_df = pd.DataFrame(coefs, columns=data.feature_names,\n",
    "                       index = ['linear', 'ridge', 'lasso', 'elastic'])\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "규제계수 $\\alpha$를 튜닝하지 않으면, 아래와 같이 일반 선형회귀보다 규제화된 선형회귀가 더 성능이 않좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48490866359057994"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] 당뇨 데이터에 대한 Ridge 모델에 대해 규제계수 $\\alpha$를 튜닝해서, Linear Regressor 보다 테스트 데이터에 대해 더 좋은 $R^2$을 갖는 모델을 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.1,\n",
       " 'R2tr': 0.4918283729062707,\n",
       " 'R2te': 0.4918283729062707,\n",
       " 'model': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = {}\n",
    "alls['a'], alls['R2tr'], alls['R2te'] = [], [], []\n",
    "best = {}\n",
    "s = 0\n",
    "for i in range(-4, 2):\n",
    "    a = 10**i\n",
    "    m = Ridge(alpha=a)\n",
    "    m.fit(X_train, y_train)\n",
    "    R2tr = m.score(X_test, y_test)\n",
    "    R2te = m.score(X_test, y_test)\n",
    "    alls['a'].append(a)\n",
    "    alls['R2tr'].append(R2tr)\n",
    "    alls['R2te'].append(R2te)\n",
    "    if R2te > s:\n",
    "        s = R2te\n",
    "        best['a'] = a\n",
    "        best['R2tr'] = R2tr\n",
    "        best['R2te'] = R2te\n",
    "        best['model'] = m\n",
    "        \n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>R2tr</th>\n",
       "      <th>R2te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.484972</td>\n",
       "      <td>0.484972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>0.485442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.487060</td>\n",
       "      <td>0.487060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.491828</td>\n",
       "      <td>0.491828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.438401</td>\n",
       "      <td>0.438401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.156424</td>\n",
       "      <td>0.156424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a      R2tr      R2te\n",
       "0   0.0001  0.484972  0.484972\n",
       "1   0.0010  0.485442  0.485442\n",
       "2   0.0100  0.487060  0.487060\n",
       "3   0.1000  0.491828  0.491828\n",
       "4   1.0000  0.438401  0.438401\n",
       "5  10.0000  0.156424  0.156424"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "alldf = pd.DataFrame(alls)\n",
    "alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.1,\n",
       " 'R2tr': 0.4918283729062707,\n",
       " 'R2te': 0.4918283729062707,\n",
       " 'model': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = {}\n",
    "alls['a'], alls['R2tr'], alls['R2te'] = [], [], []\n",
    "best = {}\n",
    "s = 0\n",
    "for a in [.3, .2, .1, .08, .06]:\n",
    "    m = Ridge(alpha=a)\n",
    "    m.fit(X_train, y_train)\n",
    "    R2tr = m.score(X_test, y_test)\n",
    "    R2te = m.score(X_test, y_test)\n",
    "    alls['a'].append(a)\n",
    "    alls['R2tr'].append(R2tr)\n",
    "    alls['R2te'].append(R2te)\n",
    "    if R2te > s:\n",
    "        s = R2te\n",
    "        best['a'] = a\n",
    "        best['R2tr'] = R2tr\n",
    "        best['R2te'] = R2te\n",
    "        best['model'] = m\n",
    "        \n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] Lasso를 튜닝하여 LinearRegressor보다 더 좋은 성능을 갖도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.1,\n",
       " 'R2tr': 0.501975882135411,\n",
       " 'R2te': 0.501975882135411,\n",
       " 'model': Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "       normalize=False, positive=False, precompute=False, random_state=None,\n",
       "       selection='cyclic', tol=0.0001, warm_start=False)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = {}\n",
    "alls['a'], alls['R2tr'], alls['R2te'] = [], [], []\n",
    "best = {}\n",
    "s = 0\n",
    "for i in range(-4, 2):\n",
    "    a = 10**i\n",
    "    m = Lasso(alpha=a)\n",
    "    m.fit(X_train, y_train)\n",
    "    R2tr = m.score(X_test, y_test)\n",
    "    R2te = m.score(X_test, y_test)\n",
    "    alls['a'].append(a)\n",
    "    alls['R2tr'].append(R2tr)\n",
    "    alls['R2te'].append(R2te)\n",
    "    if R2te > s:\n",
    "        s = R2te\n",
    "        best['a'] = a\n",
    "        best['R2tr'] = R2tr\n",
    "        best['R2te'] = R2te\n",
    "        best['model'] = m\n",
    "        \n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.1,\n",
       " 'R2tr': 0.501975882135411,\n",
       " 'R2te': 0.501975882135411,\n",
       " 'model': Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "       normalize=False, positive=False, precompute=False, random_state=None,\n",
       "       selection='cyclic', tol=0.0001, warm_start=False)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = {}\n",
    "alls['a'], alls['R2tr'], alls['R2te'] = [], [], []\n",
    "best = {}\n",
    "s = 0\n",
    "for a in [.3, .2, .1, .08, .06]:\n",
    "    m = Lasso(alpha=a)\n",
    "    m.fit(X_train, y_train)\n",
    "    R2tr = m.score(X_test, y_test)\n",
    "    R2te = m.score(X_test, y_test)\n",
    "    alls['a'].append(a)\n",
    "    alls['R2tr'].append(R2tr)\n",
    "    alls['R2te'].append(R2te)\n",
    "    if R2te > s:\n",
    "        s = R2te\n",
    "        best['a'] = a\n",
    "        best['R2tr'] = R2tr\n",
    "        best['R2te'] = R2te\n",
    "        best['model'] = m\n",
    "        \n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        , -151.41550421,  540.85933829,  337.22472854,\n",
       "        -85.19030645,   -0.        , -262.90345036,    0.        ,\n",
       "        418.24822392,    9.92430726])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['model'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] 정규화되지 않은 보스턴집값 데이터에서 정규화를 수행한 후, Ridge 회귀를 적용하자.\n",
    "\n",
    "sklearn에서 제공하는 Scaler는 3가지가 있다:\n",
    "1. MinMaxScaler: $X' = \\cfrac {X - X.min()}{X.max() - X.min()}$\n",
    "2. StandardScaler: $X' = \\cfrac {X - X.mean()}{X.std()}$\n",
    "3. RobustScaler: $X' = \\cfrac {X - X.median()}{X.IQR()}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaledXtr = scaler.fit_transform(X_train)\n",
    "scaledXte = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.0001,\n",
       " 'R2tr': 0.7480872598608888,\n",
       " 'R2te': 0.6844265404363803,\n",
       " 'model': Ridge(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls = {}\n",
    "alls['a'], alls['R2tr'], alls['R2te'] = [], [], []\n",
    "best = {}\n",
    "s = 0\n",
    "for i in range(-4, 2):\n",
    "    a = 10**i\n",
    "    m = Ridge(alpha=a)\n",
    "    m.fit(scaledXtr, y_train)\n",
    "    R2tr = m.score(scaledXtr, y_train)\n",
    "    R2te = m.score(scaledXte, y_test)\n",
    "    alls['a'].append(a)\n",
    "    alls['R2tr'].append(R2tr)\n",
    "    alls['R2te'].append(R2te)\n",
    "    if R2te > s:\n",
    "        s = R2te\n",
    "        best['a'] = a\n",
    "        best['R2tr'] = R2tr\n",
    "        best['R2te'] = R2te\n",
    "        best['model'] = m\n",
    "        \n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       " 'R2tr': [0.7480872598608888,\n",
       "  0.7480872597168551,\n",
       "  0.7480872453438752,\n",
       "  0.7480858377982795,\n",
       "  0.7479694966428208,\n",
       "  0.7438463482271056],\n",
       " 'R2te': [0.6844265404363803,\n",
       "  0.6844248492450093,\n",
       "  0.6844079428446691,\n",
       "  0.6842394366676355,\n",
       "  0.6826140350346134,\n",
       "  0.6709175158547647]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일반적인 regressor 사용방법\n",
    "SVR, DecisionTreeRegress, RandomForestRegressor, GradientBoostingRegressor ... 이런 모든 회귀용(target이 연속형) 모델의 일반적인 사용법은 이전에 배운 LinearRegressor, Ridge, Lasso 등과 동일하다.\n",
    "\n",
    "물론 모델의 알고리즘에 따라 설정해야 할 하이퍼파라미터가 달라지는 것은 예외로 한다.\n",
    "\n",
    "사용법:\n",
    "1. 모델 instance 생성: m = Ridge()\n",
    "2. 모델 학습: m.fit(X_train, y_train)\n",
    "3. 모델 평가: m.score(X_test, y_test)\n",
    "4. 모델 예측: m.predict(X_test)\n",
    "5. 회귀 계수: m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quiz] 보스턴 집값 데이터에 대해:\n",
    "1. train / test를 나누고\n",
    "2. scaling 없이할 때, knn regressor를 이용하여 최상의 k, R2을 구하시오\n",
    "3. RobustScaler를 사용할 때, 2번과 같은 작업을 수행하고 결과를 비교하시오.\n",
    "\n",
    "회귀모델에 대한 평가지표:\n",
    "1. $R^2 = 1 - \\cfrac {SSE}{SST}$\n",
    "2. MSE: loss이자 평가지표\n",
    "3. $MAE = \\cfrac 1 n \\sum |y_i - \\hat y_i|$\n",
    "4. $RMSE = \\sqrt{MSE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 3, 'R2': 0.6946008632462907, 'm': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                    weights='uniform')}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.481494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.694601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.639665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.570995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.514882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.514995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k        R2\n",
       "0   1  0.481494\n",
       "1   3  0.694601\n",
       "2   5  0.639665\n",
       "3   7  0.570995\n",
       "4   9  0.514882\n",
       "5  11  0.514995"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "def kNNtuner(ks, xtr, ytr, xts, yts):\n",
    "    best = {}\n",
    "    scores = {}\n",
    "    scores['k'] = []\n",
    "    scores['R2'] = []\n",
    "    bs = 0\n",
    "    for k in ks:\n",
    "        m = KNeighborsRegressor(k).fit(xtr, ytr)\n",
    "        R2 = m.score(xts, yts)\n",
    "        scores['k'].append(k)\n",
    "        scores['R2'].append(R2)\n",
    "        if R2 > bs:\n",
    "            bs = R2\n",
    "            best['k'] = k\n",
    "            best['R2'] = R2\n",
    "            best['m'] = m\n",
    "    \n",
    "    import pandas as pd\n",
    "    scores = pd.DataFrame(scores)\n",
    "    \n",
    "    return best, scores\n",
    "\n",
    "best, scores = kNNtuner(ks, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(best)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 3, 'R2': 0.7293736562378218, 'm': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                    weights='uniform')}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.445515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.729374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.722990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.684632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.707657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k        R2\n",
       "0   1  0.445515\n",
       "1   3  0.729374\n",
       "2   5  0.722990\n",
       "3   7  0.702703\n",
       "4   9  0.684632\n",
       "5  11  0.707657"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "mns = RobustScaler().fit(X_train)\n",
    "X_train_scaled = mns.transform(X_train)\n",
    "X_test_scaled = mns.transform(X_test)\n",
    "\n",
    "best, scores = kNNtuner(ks, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(best)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
